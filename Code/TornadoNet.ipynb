{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b2feab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TornadoNet dataset generated: (4400, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_tornado_samples(label, n, center):\n",
    "    return pd.DataFrame({\n",
    "        \"storm_relative_helicity\": np.random.normal(center[\"srh\"], 30, n),\n",
    "        \"CAPE\":                     np.random.normal(center[\"cape\"], 400, n),\n",
    "        \"lifted_condensation_level\": np.random.normal(center[\"lcl\"], 150, n),\n",
    "        \"bulk_wind_shear\":         np.random.normal(center[\"shear\"], 3.0, n),\n",
    "        \"significant_tornado_param\": np.random.normal(center[\"stp\"], 0.4, n),\n",
    "        \"tornado_binary\":          label\n",
    "    })\n",
    "\n",
    "midwest_supercell = generate_tornado_samples(1, 1200, {\n",
    "    \"srh\": 320, \"cape\": 2800, \"lcl\": 850, \"shear\": 20, \"stp\": 2.5\n",
    "})\n",
    "\n",
    "southern_plains_high_lcl = generate_tornado_samples(0, 900, {\n",
    "    \"srh\": 180, \"cape\": 2800, \"lcl\": 1700, \"shear\": 18, \"stp\": 0.9\n",
    "})\n",
    "\n",
    "cool_saturated_dud = generate_tornado_samples(0, 700, {\n",
    "    \"srh\": 220, \"cape\": 900, \"lcl\": 700, \"shear\": 10, \"stp\": 0.5\n",
    "})\n",
    "\n",
    "classic_tornado_day = generate_tornado_samples(1, 1000, {\n",
    "    \"srh\": 350, \"cape\": 3200, \"lcl\": 800, \"shear\": 22, \"stp\": 3.0\n",
    "})\n",
    "\n",
    "marginal_case = generate_tornado_samples(1, 600, {\n",
    "    \"srh\": 250, \"cape\": 2300, \"lcl\": 1000, \"shear\": 14, \"stp\": 1.5\n",
    "})\n",
    "\n",
    "# --- Final Assembly ---\n",
    "data = pd.concat([\n",
    "    midwest_supercell,\n",
    "    southern_plains_high_lcl,\n",
    "    cool_saturated_dud,\n",
    "    classic_tornado_day,\n",
    "    marginal_case\n",
    "])\n",
    "data = data.clip(lower=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data.to_csv(\"dataset/tornado_data.csv\", index=False)\n",
    "\n",
    "print(\"TornadoNet dataset generated:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc392ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\meher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8288 - loss: 0.4123 - val_accuracy: 0.9529 - val_loss: 0.2193\n",
      "Epoch 2/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9632 - loss: 0.1959 - val_accuracy: 0.9935 - val_loss: 0.1452\n",
      "Epoch 3/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.1871 - val_accuracy: 0.9935 - val_loss: 0.1412\n",
      "Epoch 4/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.1746 - val_accuracy: 0.9903 - val_loss: 0.1442\n",
      "Epoch 5/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9771 - loss: 0.1722 - val_accuracy: 0.9919 - val_loss: 0.1355\n",
      "Epoch 6/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9747 - loss: 0.1730 - val_accuracy: 0.9935 - val_loss: 0.1351\n",
      "Epoch 7/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9749 - loss: 0.1662 - val_accuracy: 0.9919 - val_loss: 0.1368\n",
      "Epoch 8/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.1665 - val_accuracy: 0.9919 - val_loss: 0.1354\n",
      "Epoch 9/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9746 - loss: 0.1697 - val_accuracy: 0.9903 - val_loss: 0.1339\n",
      "Epoch 10/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9733 - loss: 0.1714 - val_accuracy: 0.9919 - val_loss: 0.1370\n",
      "Epoch 11/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9765 - loss: 0.1743 - val_accuracy: 0.9919 - val_loss: 0.1352\n",
      "Epoch 12/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.1708 - val_accuracy: 0.9919 - val_loss: 0.1398\n",
      "Epoch 13/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.1699 - val_accuracy: 0.9903 - val_loss: 0.1342\n",
      "Epoch 14/15\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.1644 - val_accuracy: 0.9919 - val_loss: 0.1373\n",
      "WARNING:tensorflow:From c:\\Users\\meher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.1302\n",
      "TornadoNet Accuracy: 0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rewriter <function rewrite_constant_fold at 0x0000018AD6E820C0>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"dataset/tornado_data.csv\")\n",
    "X = data.drop(\"tornado_binary\", axis=1).astype(\"float32\")\n",
    "y = data[\"tornado_binary\"].astype(\"float32\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "@register_keras_serializable()\n",
    "class CAPEAmplifier(tf.keras.layers.Layer):\n",
    "    def __init__(self, threshold=2000, scale=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.scale = scale\n",
    "\n",
    "    def call(self, inputs):\n",
    "        cape = inputs[:, 1]\n",
    "        boost = tf.sigmoid((cape - self.threshold) * self.scale)\n",
    "        mod = 1.0 + 0.3 * boost\n",
    "        return tf.expand_dims(mod, axis=-1)\n",
    "\n",
    "@register_keras_serializable()\n",
    "class LCLSuppressor(tf.keras.layers.Layer):\n",
    "    def __init__(self, threshold=1400, scale=0.002, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.scale = scale\n",
    "\n",
    "    def call(self, inputs):\n",
    "        lcl = inputs[:, 2]\n",
    "        suppression = tf.sigmoid((lcl - self.threshold) * self.scale)\n",
    "        return tf.expand_dims(1.0 - 0.25 * suppression, axis=-1)\n",
    "\n",
    "@register_keras_serializable()\n",
    "class STPActivator(tf.keras.layers.Layer):\n",
    "    def __init__(self, threshold=1.5, scale=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.scale = scale\n",
    "\n",
    "    def call(self, inputs):\n",
    "        stp = inputs[:, 4]\n",
    "        activation = tf.sigmoid((stp - self.threshold) * self.scale)\n",
    "        return tf.expand_dims(1.0 + 0.2 * activation, axis=-1)\n",
    "\n",
    "@register_keras_serializable()\n",
    "class ModulationMixer(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        cape_mod, lcl_mod, stp_mod = inputs\n",
    "        combined = cape_mod * lcl_mod * stp_mod\n",
    "        return 1.0 + 0.3 * tf.tanh(combined - 1.0)\n",
    "\n",
    "input_layer = layers.Input(shape=(5,), name=\"tornado_inputs\")\n",
    "\n",
    "x = layers.BatchNormalization()(input_layer)\n",
    "x1 = layers.Dense(64, activation=\"relu\")(x)\n",
    "x2 = layers.Dense(32, activation=\"relu\")(x1)\n",
    "x3 = layers.Dense(16, activation=\"relu\")(x2)\n",
    "base_logits = layers.Dense(1)(x3)\n",
    "\n",
    "cape_mod = CAPEAmplifier()(input_layer)\n",
    "lcl_mod  = LCLSuppressor()(input_layer)\n",
    "stp_mod  = STPActivator()(input_layer)\n",
    "mod_signal = ModulationMixer()([cape_mod, lcl_mod, stp_mod])\n",
    "\n",
    "combined_logits = layers.Add()([base_logits, mod_signal])\n",
    "final_output = layers.Activation(\"sigmoid\")(combined_logits)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=final_output)\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.05),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=15, batch_size=16, callbacks=[early_stop])\n",
    "model.save('models/TornadoNet.h5')\n",
    "import tf2onnx\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"TornadoNet Accuracy: {acc:.4f}\")\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model)\n",
    "with open(f\"models/ONNX/TornadoNet.onnx\", \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15eb5838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒªï¸ TornadoNet Scenario Evaluation:\n",
      "\n",
      "ğŸŒ©ï¸ Classic Supercell Day\n",
      "  â¤ Features     : [340, 3100, 820, 22, 2.9]\n",
      "  â¤ Predicted    : Tornado (confidence: 0.97)\n",
      "  â¤ Expected     : Tornado\n",
      "\n",
      "ğŸŒ¤ï¸ High LCL, Dry Thunderstorm\n",
      "  â¤ Features     : [190, 2700, 1750, 16, 0.8]\n",
      "  â¤ Predicted    : No Tornado (confidence: 0.02)\n",
      "  â¤ Expected     : No Tornado\n",
      "\n",
      "ğŸŒªï¸ Marginal Shear, High Instability\n",
      "  â¤ Features     : [240, 3000, 950, 12, 1.6]\n",
      "  â¤ Predicted    : Tornado (confidence: 0.98)\n",
      "  â¤ Expected     : Possibly Tornado\n",
      "\n",
      "ğŸŒ«ï¸ Cool Humid Blip\n",
      "  â¤ Features     : [210, 950, 680, 8, 0.6]\n",
      "  â¤ Predicted    : No Tornado (confidence: 0.02)\n",
      "  â¤ Expected     : No Tornado\n",
      "\n",
      "âš¡ STP-Peaked Composite Storm\n",
      "  â¤ Features     : [320, 2800, 870, 20, 3.1]\n",
      "  â¤ Predicted    : Tornado (confidence: 0.97)\n",
      "  â¤ Expected     : Tornado\n",
      "\n",
      "ğŸŒ€ Low Vorticity High CAPE\n",
      "  â¤ Features     : [270, 3200, 1000, 10, 0.9]\n",
      "  â¤ Predicted    : Tornado (confidence: 0.98)\n",
      "  â¤ Expected     : Edge Case\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "scenarios = [\n",
    "    {\n",
    "        \"label\": \"ğŸŒ©ï¸ Classic Supercell Day\",\n",
    "        \"features\": [340, 3100, 820, 22, 2.9],\n",
    "        \"expected\": \"Tornado\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ğŸŒ¤ï¸ High LCL, Dry Thunderstorm\",\n",
    "        \"features\": [190, 2700, 1750, 16, 0.8],\n",
    "        \"expected\": \"No Tornado\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ğŸŒªï¸ Marginal Shear, High Instability\",\n",
    "        \"features\": [240, 3000, 950, 12, 1.6],\n",
    "        \"expected\": \"Possibly Tornado\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ğŸŒ«ï¸ Cool Humid Blip\",\n",
    "        \"features\": [210, 950, 680, 8, 0.6],\n",
    "        \"expected\": \"No Tornado\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"âš¡ STP-Peaked Composite Storm\",\n",
    "        \"features\": [320, 2800, 870, 20, 3.1],\n",
    "        \"expected\": \"Tornado\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ğŸŒ€ Low Vorticity High CAPE\",\n",
    "        \"features\": [270, 3200, 1000, 10, 0.9],\n",
    "        \"expected\": \"Edge Case\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Evaluate ---\n",
    "print(\"\\nğŸŒªï¸ TornadoNet Scenario Evaluation:\\n\")\n",
    "for case in scenarios:\n",
    "    x = np.array(case[\"features\"], dtype=\"float32\").reshape(1, -1)\n",
    "    pred = model(x).numpy()[0][0]\n",
    "    verdict = (\n",
    "        \"Tornado\" if pred > 0.55 else\n",
    "        \"Possibly Tornado\" if 0.4 < pred <= 0.55 else\n",
    "        \"No Tornado\"\n",
    "    )\n",
    "\n",
    "    print(f\"{case['label']}\")\n",
    "    print(f\"  â¤ Features     : {case['features']}\")\n",
    "    print(f\"  â¤ Predicted    : {verdict} (confidence: {pred:.2f})\")\n",
    "    print(f\"  â¤ Expected     : {case['expected']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
